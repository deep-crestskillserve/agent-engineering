{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8cbf1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict, List, Dict, Any, Optional\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.agent_toolkits import PlayWrightBrowserToolkit\n",
    "from langchain_community.tools.playwright.utils import create_async_playwright_browser\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph.message import add_messages\n",
    "from pydantic import BaseModel, Field\n",
    "from IPython.display import Image, display\n",
    "import gradio as gr\n",
    "import uuid\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780ebe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f99c08d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "llm_1 = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", google_api_key=google_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "622f9cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First define a structured output\n",
    "\n",
    "class EvaluatorOutput(BaseModel):\n",
    "    feedback: str = Field(description=\"Feedback on the assistant's response\")\n",
    "    success_criteria_met: bool = Field(description=\"Whether the success criteria have been met\")\n",
    "    user_input_needed: bool = Field(description=\"True if more input is needed from the user, or clarifications, or the assistant is stuck\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb582847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The state\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[List[Any], add_messages]\n",
    "    success_criteria: str\n",
    "    feedback_on_work: Optional[str]\n",
    "    success_criteria_met: bool\n",
    "    user_input_needed: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9672fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get our async Playwright tools\n",
    "# If you get a NotImplementedError here or later, see the Heads Up at the top of the 3_lab3 notebook\n",
    "\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "async_browser =  create_async_playwright_browser(headless=False)  # headful mode\n",
    "toolkit = PlayWrightBrowserToolkit.from_browser(async_browser=async_browser)\n",
    "tools = toolkit.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "436bb3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LLMs\n",
    "\n",
    "worker_llm = llm_1\n",
    "worker_llm_with_tools = worker_llm.bind_tools(tools)\n",
    "\n",
    "evaluator_llm = llm_1\n",
    "evaluator_llm_with_output = evaluator_llm.with_structured_output(EvaluatorOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b80cac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The worker node\n",
    "\n",
    "def worker(state: State) -> Dict[str, Any]:\n",
    "    system_message = f\"\"\"You are a helpful assistant that can use tools to complete tasks.\n",
    "    You keep working on a task until either you have a question or clarification for the user, or the success criteria is met.\n",
    "    This is the success criteria:\n",
    "    {state['success_criteria']}\n",
    "    You should reply either with a question for the user about this assignment, or with your final response.\n",
    "    If you have a question for the user, you need to reply by clearly stating your question. An example might be:\n",
    "\n",
    "    Question: please clarify whether you want a summary or a detailed answer\n",
    "\n",
    "    If you've finished, reply with the final answer, and don't ask a question; simply reply with the answer.\n",
    "    \"\"\"\n",
    "    \n",
    "    if state.get(\"feedback_on_work\"):\n",
    "        system_message += f\"\"\"\n",
    "    Previously you thought you completed the assignment, but your reply was rejected because the success criteria was not met.\n",
    "    Here is the feedback on why this was rejected:\n",
    "    {state['feedback_on_work']}\n",
    "    With this feedback, please continue the assignment, ensuring that you meet the success criteria or have a question for the user.\"\"\"\n",
    "    \n",
    "    # Add in the system message\n",
    "\n",
    "    found_system_message = False\n",
    "    messages = state[\"messages\"]\n",
    "    for message in messages:\n",
    "        if isinstance(message, SystemMessage):\n",
    "            message.content = system_message\n",
    "            found_system_message = True\n",
    "    \n",
    "    if not found_system_message:\n",
    "        messages = [SystemMessage(content=system_message)] + messages\n",
    "    \n",
    "    # Invoke the LLM with tools\n",
    "    response = worker_llm_with_tools.invoke(messages)\n",
    "    \n",
    "    # Return updated state\n",
    "    return {\n",
    "        \"messages\": [response],\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
